This file collects proofs of separation results in our partial order.

—–——

Part I. No non-relational preservation criterion implies any
relational preservation criterion.

—–——

This section shows that no non-relational preservation criterion
implies any relational preservation criterion. We do this
constructively, by showing a source and a target language and a
compiler between them such that:

1. The compiler satisfies the /strongest/ non-relational preservation
criterion (robust hyperproperty preservation, RHP).

2. The compiler does not satisfy the /weakest/ relational preservation
criterion (Robust 2-relational safety preservation or
R2rSC). Actually, our languages satisfy the conditions that make R2rSC
imply Robust Trace Equivalence Preservation (RTEP), so we simply show
that the compiler does not satisfy RTEP.

Theorem 1: There is a compiler between two determinate, sequence total
languages that has RHP, but not RTEP.

Proof: See below.


Corollary (main result): No non-relational preservation criterion
implies any relational preservation criterion for all compilers.

Proof: Suppose not. Then, there is a non-relational criterion X and a
relational criterion Y such that X => Y for all compilers. Since RHP
is the strongest non-relational criterion and R2rSC is the weakest
relational criterion, this also implies that RHP => R2rSC for all
compilers. In particular, this holds for the compiler of theorem
1. Since the compiler of Theorem 1 is RHP, it must also be
R2rSC. Hence, that compiler has RTEP, which contradicts Theorem
1. Qed.

——–
Proof of Theorem 1
——–

Our source language is a standard while language with read and write
to standard I/O. It has traces of length exactly 2: One input (read)
followed by one output (write). This language works over integers (not
natural numbers) and has exactly two programs, P₁ and P₂, shown below,
that differ only in a bit of dead code.

P₁:
x = read();
y = f();
write (x + y)

P₂:
x = read();
y = f();
... some dead code here ...
write (x + y)

Here, f() is a function provided by the context.

The target language is the same, but additionally allows the context
to read the compiled /code/ as a value.

The compiler under consideration, called ↓, is the identity. 

Lemma 2: The compiler ↓ is RHP.

Proof. Following the alternate characterization RHP' of RHP, we need
to show that ∀Cₜ P. ∃Cₛ. behav(Cₛ[P]) = behav(Cₜ[P↓]). Pick a Cₜ and a
P. Note that P↓ = P by definition of the compiler. For the Cₛ, pick
the Cₜ, but wherever Cₜ reads the code of P↓, just hard-code P (which
is the same as P↓). [Note: This works because we allow Cₛ to depend on
P.] It is trivial to see that Cₛ[P] and Cₜ[P] have exactly the same
behaviors.

Lemma 3: The compiler ↓ is not RTEP.

Proof. Since P₁ and P₂ differ only in dead code, which a source
context cannot examine, it is trivially the case that
∀Cₛ. behav(Cₛ[P₁]) = behav(Cₛ[P₂]).

On the other hand, we can construct a target context Cₜ whose f()
checks whether the compiled code is P₁ or P₂ and returns 0 or 1,
respectively. Then, Cₜ[P₁] has the trace [read 0, write 0], while
Cₜ[P₂] does not have this trace (instead, it has the trace [read 0,
write 1] that Cₜ[P₁] does not have). Hence, behav(Cₜ[P₁]) ≠
behav(Cₜ[P₂]). So the compiler is not RTEP.

Qed.

Theorem 1 follows immediately from Lemmas 2 and 3.

——–
The more general story
——–

The more general situation here is that if we take any source language
in which the context cannot examine the code and compile it to a
target language that is similar, but where the context can
additionally examine the code, then the identity compiler satisfies
every non-relational criterion including RHP, since /for a single
program/, the target context's additional ability to observe code is
inconsequential. (More formally, non-relational preservation
criterion, including RHP, allow the simulating source context Cₛ to
depend on the compiler program P, so its code can be hard-coded into
Cₛ wherever Cₜ examines the code.)

However, it is extremely unlikely that this compiler satisfies any
relational preservation criterion since the target context can branch
on the program being executed and provide different values.


—–——

Part II. Robust safety property preservation (RSP) does not imply
Robust 2-hypersafety preservation (R2HSP).

—–——

We show by counterexample that robust safety property preservation
(RSP) does not imply Robust 2-hypersafety preservation (R2HSC).

Source language: Works over integers, has traces of length exactly 2
(read input, write output), and has exactly one program P:

P:  
x = read;
y = f();
write x+y

where f() is a function provided by the context.

Target language: Same as source, but the context additionally has the
ability to directly read P's private variables (like x).

Compiler: Identity.
 
This compiler satisfies robust safety property preservation (RSP). The
reason is that the source P can generate every trace given an
appropriate source context.  (To generate the trace [read a, write b],
take the context whose f() returns b-a.)

However, this compiler cannot satisfy robust 2-hypersafety
preservation (R2HSP). Here's a concrete example. Consider the
2-hypersafety property defined by pairs of bad traces of the form
([read a1, write b1], [read a2, write b2]) where a1 <> a2 but b1 = b2.

In the source, any f() defined by the context must be a constant
function. This is because the context has no access to the input
stream or P's local variables, hence f()'s result can't depend on any
change-able quantity. If f() returns c, then (b2 - b1) = (a2 + c) -
(a1 + c) = (a2 - a1). Hence, b2 <> b1 when a2 <> a1.

In the target, one can write a specific context function f() that
breaks this 2-hypersafety property: f() { return (-x); }. This
function reads P's local variable x (which it can in the target) and
returns the negation of that. Hence, with this context, P always
writes x - x = 0, so this context breaks the 2-hypersafety property.

—–——

Part III. RTEP does not imply any other preservation criterion in our
partial order.

—–——

We show that RTEP does not imply any other preservation criterion in
our partial order. We do this by showing that RTEP implies neither
robust safety property preservation (RSP) nor robust dense property
preservation (RDP), which are the two other minimas of our partial
order.

Theorem 4: There is a RTEP compiler that is not RSP and that is not
RDP.

Proof. See below.


Corollary (main result): RTEP does not imply any other criterion in
our partial order.

Proof. Suppose, for the sake of contradiction, that RTEP implies some
criterion X. In our partial order, every criterion is either above RSP
or RDP. Thus, RTEP must imply either RSP or RDP. This violates Theorem
4. Contradiction. Qed.

——–
Proof of Theorem 4
——–

Consider a language operating over booleans, having operators OR, AND,
NOT, and only one trace action, write. Every program simply writes an
infinite trace of outputs.

...
y1 = ...;
write y1;
y2 = ...;
write y2;
...

where ... are pure computations consisting of the boolean operators
(some of these may be provided by the context). 

Consider a compiler ↓ from this language to itself, that transposes
true to false and vice-versa. The compiler replaces AND with OR, and
OR with AND, thus dualizing every program and every trace. Basically,
↓ replaces the program above with the program

...
y1 = ...;
write y1;
y2 = ...;
write y2;
...

where the ... in the compiled program are obtained from those in the
original program by De Morgan dualization of all expressions. Note
that the original program has a trace [write a₁, write a₂, ...] with
context C iff the compiled program has the trace [write (¬a₁), write
(¬a₂), ...] in the context dual to C.

Lemma 5: The compiler ↓ is RTEP.

Proof: Suppose that for ∀ Cₛ. behav(Cₛ[P₁]) = behav(Cₛ[P₂]). We want
to show that ∀ Cₜ. behav(Cₜ[P₁↓]) = behav(Cₜ[P₂↓]). Suppose for
contradiction that this is not the case. Then, wlog, there is some Cₜ
and some trace t = [write a₁, ...] such that Cₜ[P₁↓] ↝ t but ¬(Cₜ[P₂̣↓]
↝ t). Let Cₛ be the dual context of Cₜ. Let t' = [write (¬a₁),
...]. It is clear that Cₛ[P₁] ↝ t' but ¬(Cₛ[P₂̣] ↝ t'). Hence,
behav(Cₛ[P₁] ≠ behav(Cₛ[P₂]). Contradiction. Qed.

Lemma 6: The compiler ↓ is not RSP and it is not RDP.

Proof: Consider the program P

P:
y1 = true;
write y1;
y2 = true;
write y2;
...

and its compilation

P↓:
y1 = false;
write y1;
y2 = false;
write y2;
...


Proof of (not RSP):

P (robustly) satisfies the satisfies the safety property "never output
false", which is formalized by the bad prefixes {[write false], [write
true, write falsė], [write true, write true, write false],
...}. However, P↓ does not satisfy this safety property, since it can,
in particular, produce the bad prefix [write false]. Hence,
↓ is not RSP.

Proof of (not RDP):

P (robustly) satisfies the dense property "on every infinite trace,
eventually write true". However, P↓ above does not satisfy this
property. Hence, ↓ is not RDP.

Qed.

Proof of Theorem 4: It is immediate from Lemmas 5 and 6 that ↓ is RTEP
but neither RSP nor RDP.

—–——

Part IV. Robust k-hypersafety preservation (RkHSP) does not imply
robust (k+1)-hypersafety preservation (R(k+1)HSP) for any k.

—–——

We describe a concrete compiler, parametric in k, that has robust
k-hypersafety preservation (RkHSP) but not robust (k+1)-hypersafety
preservation (R(k+1)HSP) for any k.

Our source language is a standard while language with read and write
to standard I/O. It has traces of length exactly 2: One input (read)
followed by one output (write). This language's inputs are always in
the range [1, ..., k+1], while its internal values and outputs are
reals. The language has exactly one program, P, shown below. The
context provides the functions f₁() ... fₖ().

P:
x = read();
switch (x) {
  case x = i where 1 ≤ i ≤ k:
     y = x + (∑ {fⱼ() | 1 ≤ j ≤ k ∧ i ≠ j});
     break;
  case x = k + 1:
     y = x + f₁();
}
write (y)


Our target language is similar to the source, but the context has
access to the private state of the program, e.g., it can read the
local variable x. In the source, the context lacks this capability.

The compiler under consideration, ↓, is the identity, i.e., it maps P
to P.

Lemma 7: The compiler ↓ is RkHSP.

Proof. We prove this by showing that for any finite k-set of prefixes
{ [read(a₁), write(b₁)], ..., [read(aₖ), write(bₖ)] } that the program
Cₜ[P] can produce (for some target context Cₜ), there is some source
context Cₛ that produces these k prefixes as well. This property
immediately implies that the compiler has RkHSP.

To prove this property, note that if all k prefixes [read(a₁),
write(b₁)], ..., [read(aₖ), write(bₖ)] can be produced by the target,
then, since the target is still deterministic, we must have ∀i,j. aᵢ =
aⱼ => bᵢ = bⱼ. So, we can assume wlog that all aᵢ's are distinct. It
follows now that I = {a₁,...,aₖ} is a k-subset of {1,...,k+1}, so I
must be missing exactly one element of {1, ..., k+1}.

Case: The missing element is k+1. Then, I = {a₁,...,aₖ} =
{1,...,k}. We can assume wlog (by reordering I if needed) that aᵢ =
i. We now set up a system of linear equations whose solution gives us
the Cₛ. Let xᵢ be a variable that represents the value of fᵢ(). (Note
that fᵢ() must be a constant function in the source context). Then, we
get the equations:

     x₂ + ... + x_{k-1} + xₖ = b₁ - a₁
x₁ +    + ... + x_{k-1} + xₖ = b₂ - a₂
...
x₁ + x₂ + ... + x_{k-1} +    = bₖ - aₖ

This system has a unique solution. To see this, first add all the
equations. This gives (k-1) (x₁ + ... + xₖ) = (b₁ + ... + bₖ) - (a₁ +
... + aₖ). This yields an equation x₁ + ... + xₖ = c for some
c. Subtracting the first equation above from this gives us
x₁. Subtracting the second equation gives x₂ and so on. Hence, we have
a value (=xᵢ) that each fᵢ() must return in the source in order to
produce the required outcome. This is the required Cₛ.

Case: The missing element is 1. Then, I = {a₁,...,aₖ} =
{2,...,k+1}. Assume wlog that a₁ = 2, ..., aₖ = k+1. Then, as before,
we get the equations:

x₁ +    + ... + x_{k-1} + xₖ = b₁ - a₁
...
x₁ + x₂ + ... + x_{k-1} +    = b_{k-1} - a_{k-1}
x₁                           = bₖ - aₖ

This set of equations also has a solution. First, the last equation
directly gives x₁. Now subtract the last equation from all the
previous k-1 equations. This yields exactly k-1 /cyclic/ equations in
k-1 variables x₂,...,xₖ. These can be solved exactly as in the
previous case.

Case: The missing element lies between 2 and k (both inclusive). Wlog
assume that the missing element is k. Then, I = {a₁,...,aₖ} =
{1,...,k-1,k+1}. Again, wlog, assume that a₁ = 1, ..., a_{k-1} = k-1
and aₖ = k+1. Then, we get the equations:

     x₂ + ... + x_{k-2} + x_{k-1} + xₖ = b₁ - a₁
x₁ +    + ... + x_{k-2} + x_{k-1} + xₖ = b₂ - a₂
...
x₁ + x₂ + ... + x_{k-2} +         + xₖ = b_{k-1} - a_{k-1}
x₁                                     = bₖ - aₖ

Solving these equations is also easy. x₁ is given from the last
equation. Adding the first and last equation gives the value of x₁ +
... + xₖ. Subtracting the remaining equations from this one by one
yields x₂,...,x_{k-1}. Then, xₖ follows from the first equation.

Qed.

—–

Lemma 8: The compiler ↓ is not R(k+1)HSP.

Proof. We construct a concrete (k+1) prefix set S and a Cₜ such Cₜ[P↓]
has all prefixes of S, but no Cₛ[P] can exhibit all prefixes of S. The
proof relies on the fact that, in the source, each of f₁(),...,fₖ()
must be a constant function, so we can have k+1 inconsistent equations
for these k constants. In the target, these don't have to be constant
since any fᵢ can return a value based on the private input x.

Here's the concrete example. Let c be the constant k-1. Consider the
prefix set:

S = {
 [1, 1 + c],
 [2, 2 + c],
 ...
 [k, k + c]
 [k + 1, k + 1]
}

So, for inputs x = 1 ... k, the output is c (or k-1) more than the
input, but for input k + 1, the output is k + 1 itself.

Here is a target context Cₜ that generates this prefix set S:

f₁() = if P.x = k + 1 then 0 else 1      // P.x is the private x of P
f₂() = 1
...
fₖ() = 1

The function f₁() returns 1 except when the private input x is k+1,
when it returns 0. It is easy to see that for input x between 1 ... k,
the output of P is exactly x + (k-1), while for input x = k+1, the
output of P is k+1 + f₁() = k+1 + 0 = k+1. Hence, Cₜ[P↓] generates the
entire prefix set S.

On the other hand, Cₛ[P] cannot generate all prefixes of S for any
Cₛ. To see this, suppose for the sake of contradiction that some Cₛ[P]
can actually generate all prefixes of S. Let fᵢ() = xᵢ. We get the
equations:

     x₂ + ... + x_{k-1} + xₖ = (1 + k-1) - 1 = k - 1
x₁ +    + ... + x_{k-1} + xₖ = (2 + k-1) - 2 = k - 1
...
x₁ + x₂ + ... + x_{k-1}      = (k + k-1) - k = k - 1
x₁                           = (k+1) - (k+1) = 0

However, these equations are inconsistent. The first k equations
(which are cyclic) force that x₁ = ... = xₖ = 1, while the last
equation requires x₁ = 0. Contradiction.

Qed.

It follows from Lemmas 7 and 8 that ↓ is RkHSP but not R(k+1)HSP.


—–——

Part V. RTEP does not imply any other preservation criterion in our
partial order, even when compiler correctness is required.

—–——

We show a stronger result than Part III, namely that RTEP does not
imply any other preservation criterion in our partial order even if we
require compiler correctness. We do this by showing that
RTEP+correctness implies neither robust safety property preservation
(RSP) nor robust dense property preservation (RDP), which are the two
minimas of our partial order.

Theorem 5: There is a RTEP, correct compiler that is not RSP and that
is not RDP.

Proof. See below.


Corollary (main result): FA+correctness does not imply any other
criterion in our partial order.

Proof. Suppose, for the sake of contradiction, that FA+correctness
implies some criterion X. In our partial order, every criterion is
either above RSC or RLC. Thus, FA must imply either RSC or RLC. This
violates Theorem 4. Contradiction.

Qed.

——–
Proof of Theorem 5
——–

Consider a language operating over booleans and 1-bit integers 0 and
1, having a write operation (which goes on the trace). Every program
has an infinite trace of writes of booleans. In the source, the only
programs are those that get a 1-bit value from the context by calling
a context-defined function f() and then output true:

x = f()
write true
write true
write true
...

All source programs have exactly one trace in any context. This trace
is [write(true), write(true),...].

Consider a compiler ↓ from this language to a target where the
integers have been expanded from 1-bit to 2-bits, so the reads of the
program are in the set {0,1,2,3}. The compiler ↓ changes a program of
the above form to:

x = f()
if (x = 0 or x = 1)
then write true; write true; write true; ...
else write false; write false; write false; ...

Lemma 9: The compiler ↓ is RTEP.

Proof: Trivial since the source has exactly one program. Qed.

Lemma 10: The compiler ↓ is correct.

Proof: From the definition of the compiler, we see that if f() in the
target returns either 0 or 1, then the compiled program outputs true
forever, like the source program. When we consider correctness, the
target context must correspond to a source context, and hence f() must
return something that a source context can. But a source context can
only return 0 or 1. Qed.

Lemma 11: The compiler ↓ is not RSP and it is not RDP.

Proof: Every source program robustly satisfies the safety property
"never write false". No compiled program robustly satisfies this
property since the target context whose f() returns 2 causes every
compiled program to write false. Hence, ↓ is not RSP.

Every source program robustly satisfies the dense property "on an
infinite trace, eventually write true". By the same argument as above,
no compiled program robustly satisfies this propertly. Hence, ↓ is not
RDP.  Qed.

Proof of Theorem 5: It is immediate from Lemmas 9, 10 and 11 that ↓ is
RTEP and correct, but neither RSP nor RDP.

